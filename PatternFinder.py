#PatternFinder.py -- Retrieve a stored object generated by FileParser, find data patterns in it

import FileReader
import sys
import pickle
import numpy as np
import pandas as pd
import hashlib
import pickle
import os
from pathlib import Path

#main:
if len(sys.argv) == 1:
  print('         Usage: retrieve a stored object generated by FileParser, find data patterns in it\n\
         Example: python PatternFinder.py testDB streamDB\n\
           testDB: file that saves the object\n\
           sreamDB: file that saves the final result')
  sys.exit(0)


with open(sys.argv[1], 'rb') as f:
  reader = pickle.load(f)

print("File size:" + str(reader.fileSize) + " Read chunk size:" + str(reader.chunkSize) + " Start offset:" + str(reader.readStartPos))

#create pandas DataFrame:
dfFile = pd.DataFrame(pd.Series(reader.fileHash))
dfFile.rename(columns={0:'count'}, inplace=True)

#add offset table to dataframe:
dfFile['offset'] = pd.Series(reader.offsetTable)

#sort hash index count:
dfFile.sort_values(['count'], ascending=[False], inplace=True)

dfFile.reset_index(inplace=True)
dfFile.rename(columns={'index':'hash_val'}, inplace=True)

#The output of DataFrame has the following form:
#File size:176 Read chunk size:16
#   hash_val  count        offset
#0       381      4  [0, 2, 6, 9]
#1         0      2        [4, 5]
#2      1660      2        [1, 7]
#3      1549      1          [10]
#4      1591      1           [8]
print(dfFile.head())

#for the top N hash count, get the byte stream for each of them
TOP_N = 5
topBytesStats = {}

def parseAndGetBytesCount(topBytesStats, dfElement):
  #open file, and jump to the start offset:
  f = open(reader.fileToBeRead, "rb")
  tempHex = [f.read(1) for i in range(0, reader.readStartPos)]

  offset = 0
  for i, val in enumerate(dfElement['offset']):
    if i == 0:
      offset = val * reader.chunkSize
    else:
      offset = (val - dfElement['offset'][i-1] - 1) * reader.chunkSize

    f.seek(offset, 1)
    byteStream = f.read(reader.chunkSize)
  
    #get sha hash value, so hash collision will be low possibility:
    ha = hashlib.sha256(byteStream).hexdigest()

    if ha not in topBytesStats:
      topBytesStats[ha] = {'stream': byteStream, 'count': 1}
    else:
      topBytesStats[ha]['count'] += 1

  f.close()


for i in range(0, TOP_N):
  parseAndGetBytesCount(topBytesStats, dfFile.iloc[i])


#create panda DataFrame:
dfStreamStats = (pd.DataFrame(topBytesStats)).transpose()
dfStreamStats.sort_values(['count'], ascending=[False], inplace=True)

print("\n")
print(dfStreamStats.head())

#add stats to FilerReader, so we can load and parse it:
reader.dfStreamStats = dfStreamStats

#save it:
if Path(sys.argv[2]).is_file():
  os.remove(sys.argv[2])
with open(sys.argv[2], 'wb') as pickler:
  pickle.dump(reader, pickler, pickle.HIGHEST_PROTOCOL)

